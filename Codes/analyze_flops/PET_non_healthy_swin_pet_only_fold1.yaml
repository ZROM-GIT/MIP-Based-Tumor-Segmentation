# Resume training or train from the start
resume_training: True
experiment_key: '2427c698a51547589d4390462a61690a'

# Path to JSON file that holds all the dataset paths
json_path: '/mnt/sda1/PET/json_datasets/non_healthy/MIPs16/MIPs16_75th_25vth_IncSplit_0_180_non_healthy_fold1.json'

# log experiment
log_experiment: True
api_key: "qLBtT61m6OQ657LxA53BPORKT"
workspace: "zrom-git"

# Saves paths
save_weights_path: '/mnt/sda1/PET/Codes/weights/swin_comparison'
save_checkpoints_path: '/mnt/sda1/PET/Codes/checkpoints/swin_comparison'

# Project & experiment details
project_name: PET
experiment_name: 'heiligerl_experiment_PET_only_fold1'
experiment_number: 0

#########################################################################################

# Constant values for yaml 
num_of_mips: &num_of_mips
    16
input_name: &input_name
    'SUV_3D'
target_name: &target_name
    'SEG_3D'

#########################################################################################
# Training Parameters
device: 0  # Number of GPU (0/1) or 'cpu'
use_amp: False  # Always uses Scaler. Always False when not training on GPU
amp_dtype: float16  # torch.(float16/bfloat16)
use_gradient_clipping: False
use_scheduler: False
save_checkpoint_every_n: 50  # Save checkpoint every epoch number
save_checkpoint_when_val_improves: True  # True/False

# Hyperparameters
batch_size: 1
epochs: 100
lr: 1e-4
shuffle_data: true
seed: 598484 # None for non-determinism

# Dataset type
dataset_arguments:
    dataset_type: Dataset  # CacheDataset for speed (more memory) / SmartCacheDataset for partial cached datasets

# Optimizer arguments
optimizer_arguments: 
    optimizer: 'AdamW'
    weight_decay: 1e-5

# Clip gradients
clip_gradients: false 
clip_arguments: 
    norm_type: 2
    max_norm: 1

# Loss function arguments
loss_function_arguments: 
    loss_function_name: 'DiceCELoss'
    include_background: false 
    
# Learning Rate Scheduler
#scheduler_arguments: 
#    scheduler: CyclicLR
#    base_lr: 1e-6
#    max_lr: 5e-4
#    mode: triangular2
#    step_size_up: 5
#    step_size_down: 15
#    gamma: 0.6
#    cycle_momentum: false

#    scheduler: StepLR
#    step_size: 20
#    gamma: 0.8

#     scheduler: CosineAnnealingLR
#     T_max: 200
#     eta_min: 1e-7

# Model arguments
model_arguments: 
    model_name: SwinUNETR
    img_size: [96, 96, 96]
    in_channels: 1
    out_channels: 2
    spatial_dim: 3
    feature_size: 48
    use_checkpoint: false
    use_v2: false
    

# Final activation 
final_activation: softmax

# Whether to use sliding window inference 
use_sliding_window_inference: ['validation'] # ['training', 'validation']
sliding_window_inference_params:
    roi_size: [96, 96, 96]
    sw_batch_size: 8
    overlap: 0.25
    mode: 'constant' # gaussian


# Metrics
metrics:
    DiceMetric: 
        include_background: false
        get_not_nans: true 
        ignore_empty: false 
    MeanIoU:
        include_background: false
        get_not_nans: true 
        ignore_empty: false         
    HausdorffDistanceMetric: {} 
metricForSaving: DiceMetric
save_val_path: '/mnt/sda1/PET/Codes/validation_predictions'
save_val_every_n: 10

# Transforms
defaultTransforms:
    LoadImaged:
        keys: 
            - SUV_3D
            - CT_3D
            - SEG_3D
        image_only: true
        ensure_channel_first: true
        dtype: 'float16'
    Orientationd:
        keys: 
            - SUV_3D
            - CT_3D
            - SEG_3D
        axcodes: 'LAS'
    NormalizeIntensityd:
        keys: 
            - SUV_3D
        nonzero: True 
    ScaleIntensityRangePercentilesd:
        keys:       
            - CT_3D
        lower: 0.5 
        upper: 99.5 
        b_min: 0.0
        b_max: 1.0 
        clip: True 
    CropForegroundd:
        keys: 
            - SUV_3D
            - CT_3D
            - SEG_3D
        source_key: CT_3D
#    ConcatItemsd: 
#        keys: 
#            - SUV_3D
#            - CT_3D
#        name: 'petct'
#        dim: 0
    onehot_bin:
        keys:
            - *target_name
        dim: 1

trainTransforms:
    RandCropByPosNegLabeld:
        keys: 
            - *input_name
            - *target_name 
        label_key: *target_name 
        spatial_size: [96, 96, 96]
        pos: 2
        neg: 1
        num_samples: 4
        image_key: *input_name 
        image_threshold: 0
    RandRotated:
        keys: 
            - *input_name
            - *target_name 
        range_x: eval('(-15. / 360 * 2. * np.pi, 15. / 360 * 2. * np.pi)')
        range_y: eval('(-15. / 360 * 2. * np.pi, 15. / 360 * 2. * np.pi)')
        range_z: eval('(-15. / 360 * 2. * np.pi, 15. / 360 * 2. * np.pi)')
        prob: 0.2 
        mode: ['bilinear', 'nearest']
    ToTensord:
        keys: 
            - *input_name
            - *target_name

valTransforms:
    ToTensord:
        keys: 
            - *input_name
            - *target_name

testTransforms: {}

# Utilities
sets: ['training', 'validation', 'test']
set2transforms:
    training: trainTransforms
    validation: valTransforms
    test: testTransforms

# Inverse transforms 
training_inverse_transforms:
    activation: False
    timing: 'pre' # pre / post metric calculation
    num_of_reverses: -1

validation_inverse_transforms:
    activation: False
    timing: 'pre' # pre / post metric calculation
    num_of_reverses: -1

test_inverse_transforms:
    activation: False
    timing: 'pre' # pre / post metric calculation
    num_of_reverses: -1


#########################################################################################

monai_metrics:
    - compute_fp_tp_probs
    - compute_froc_curve_data
    - compute_froc_score
    - compute_variance
    - VarianceMetric
    - label_quality_score
    - LabelQualityScore
    - IterationMetric
    - Cumulative
    - CumulativeIterationMetric
    - LossMetric
    - compute_meandice
    - DiceMetric
    - compute_meaniou
    - MeanIoU
    - compute_generalized_dice
    - GeneralizedDiceScore
    - compute_roc_auc
    - ROCAUCMetric
    - get_confusion_matrix
    - compute_confusion_matrix_metric
    - ConfusionMatrixMetric
    - compute_hausdorff_distance
    - compute_percent_hausdorff_distance
    - HausdorffDistanceMetric
    - compute_average_surface_distance
    - SurfaceDistanceMetric
    - compute_surface_dice
    - compute_panoptic_quality
    - SurfaceDiceMetric
    - PanopticQualityMetric
    - MSEMetric
    - MAEMetric
    - RMSEMetric
    - PSNRMetric
    - SSIMMetric
    - CumulativeAverage

nonlinearity_functions:
    - relu
    - selu
    - leaky_relu
    - tanh
    - sigmoid

probability_functions:
    - uniform_ #(torch.tensor, a=0.0, b=1.0)
    - normal_ #(torch.tensor, mean=0.0, std=1.0)
    - constant_ #(torch.tensor, val)
    - ones_ #(torch.tensor)
    - zeros_ #(torch.tensor)
    - xavier_uniform_ #(torch.tensor, gain=1)
    - xavier_normal_ #(torch.tensor, gain=1)
    - kaiming_uniform_ #(torch.tensor, a=0, mode='fan_in', nonlinearity='leaky_relu')
    - kaiming_normal_ #(torch.tensor, a=0, mode='fan_in', nonlinearity='leaky_relu')
    - trunc_normal_ #(torch.tensor, mean=0.0, std=1.0, a=-2.0, b=2.0)
    - orthogonal_ #(torch.tensor, gain=1)

lr_functions:
    - ExponentialLR #(optimizer, end_lr, num_iter, last_epoch=-1)
    - LinearLR #(optimizer, end_lr, num_iter, last_epoch=-1)
    - WarmupCosineSchedule #(optimizer, warmup_steps, t_total, cycles=0.5, last_epoch=-1, warmup_multiplier=0)
